# Hybrid RAG Chatbot Architecture Document

## 1. Overview

This document describes the architecture for the Hybrid RAG
(Retrieval-Augmented Generation) chatbot prototype. The system leverages
a **Gemini LLM**, **Gemini-compatible embeddings**, a **vector database
(Qdrant)**, and a **multi-agent framework**. It integrates both a
**local knowledge base** (scraped JSON files) and **real-time internet
search (Serper API)**.

------------------------------------------------------------------------

## 2. System Components

### 2.1 Frontend

-   **Technology**: React.js with Tailwind CSS (clean UI for chat).
-   **Functionality**:
    -   Chat interface for user input and AI responses.
    -   Conversation history display.
    -   API integration with FastAPI backend endpoints.

------------------------------------------------------------------------

### 2.2 API & Backend (Prototype Local Setup)

-   **Framework**: FastAPI (local prototype).
-   **Routes**:
    -   `/chat`: Accepts user query, routes through orchestrator agent,
        and returns AI response.
    -   `/search`: Calls Serper API for real-time web results.
    -   `/embed`: Generates embeddings using Gemini-compatible embedding
        API.
    -   `/retrieve`: Retrieves top-k documents from Qdrant.

------------------------------------------------------------------------

### 2.3 Knowledge Base

-   **Source**: 2000+ JSON documents scraped from internal/external
    websites.
-   **Storage**: Qdrant (local vector database).
-   **Indexing**:
    -   Each document chunked (≈500 tokens).
    -   Embedded with Gemini-compatible embeddings.
    -   Stored in Qdrant for similarity search.

------------------------------------------------------------------------

### 2.4 Retrieval Mechanism

-   **Hybrid RAG**:
    -   **Vector Search (Qdrant)** for semantic similarity.
    -   **Serper API** for real-time internet augmentation.
    -   Results combined and ranked before being passed to LLM.

------------------------------------------------------------------------

### 2.5 Multi-Agent Framework

The chatbot uses multiple specialized agents coordinated by an
**Orchestrator Agent**.

#### **(a) Orchestrator Agent**

-   Entry point for all user queries.
-   Decides whether to use:
    -   Knowledge Base Agent (local data),
    -   Web Search Agent (Serper API),
    -   Or a hybrid approach.
-   Ensures final response consistency.

#### **(b) Knowledge Base Agent**

-   Handles retrieval from **Qdrant vector DB**.
-   Responsibilities:
    -   Search relevant documents.
    -   Summarize key insights.
    -   Pass context to Orchestrator.

#### **(c) Web Search Agent**

-   Interfaces with **Serper API** for real-time internet search.
-   Responsibilities:
    -   Query Serper API.
    -   Filter noisy results.
    -   Return structured insights.

#### **(d) Response Generation Agent**

-   Uses **Gemini LLM** for natural language generation.
-   Responsibilities:
    -   Accept context from KB Agent + Web Agent.
    -   Generate final coherent response.
    -   Maintain tone and structure.

------------------------------------------------------------------------

## 3. Data Flow

1.  User enters query via **React Frontend** → sent to **FastAPI
    backend**.
2.  Query received by **Orchestrator Agent**.
3.  Orchestrator decides:
    -   Query KB Agent (Qdrant),
    -   Query Web Agent (Serper),
    -   Or both.
4.  Retrieved results are passed to **Response Generation Agent**.
5.  Response generated by **Gemini LLM** and returned to frontend.

------------------------------------------------------------------------

## 4. APIs Required

-   **Gemini LLM API Key** → for response generation & embeddings.
-   **Serper API Key** → for internet search augmentation.
-   **Qdrant (local)** → no external API key needed.

------------------------------------------------------------------------

## 5. Latency Optimization

-   Pre-chunk & embed JSON KB documents (offline preprocessing).
-   Cache frequently asked queries in memory.
-   Use async FastAPI endpoints for parallel KB + web search calls.
-   Limit retrieved docs to **Top-5** for response generation.

------------------------------------------------------------------------

## 6. Future Enhancements

-   Backend scaling with distributed Qdrant.
-   Caching layer (Redis) for high-frequency queries.
-   Multi-turn memory with vector store persistence.
-   Advanced ranking for hybrid retrieval results.

------------------------------------------------------------------------

## 7. Architecture Diagram (Conceptual)

    User → Frontend (React) → FastAPI API → Orchestrator Agent
       ├── Knowledge Base Agent → Qdrant Vector DB
       ├── Web Search Agent → Serper API
       └── Response Generation Agent → Gemini LLM
